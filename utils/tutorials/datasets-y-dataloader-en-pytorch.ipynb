{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd61d4d",
   "metadata": {},
   "source": [
    "# Dataset and Dataloaders with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e0e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset # To store data\n",
    "from torch.utils.data import DataLoader # To charge data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c35482",
   "metadata": {},
   "source": [
    "Las clases Dataset permiten instanciar objetos con el conjunto de datos que se van a cargar. PyTorch permite crear dos tipos distintos de datasets:\n",
    "\n",
    "* Map-style: Implementa los métodos getitem() and len() y representa un mapeo de claves/índices a valores del conjunto de datos. La clase Dataset sería un ejemplo y es el tipo de dataset que veremos.\n",
    "* Iterable-style: Implementa el método iter() y representa un iterable sobre los datos. La clase IterableDataset es un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e35ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumbersDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.samples = list(range(1, 1001))\n",
    "        self.labels = list(range(1000, 2001))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3b9d64b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "(101, 1100)\n",
      "([123, 124, 125], [1122, 1123, 1124])\n"
     ]
    }
   ],
   "source": [
    "dataset = NumbersDataset()\n",
    "print(len(dataset))\n",
    "print(dataset[100])\n",
    "print(dataset[122:125])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa4e132",
   "metadata": {},
   "source": [
    "La clase torch.utils.data.DataLoader es la clase principal para cargar los datos. A esta clase se le pasa como argumento un objeto Dataset (map-style o iterable style) y tiene varias opciones como:\n",
    "\n",
    "* Definir el orden y la forma de cargar los datos.\n",
    "* Batching automático: Se carga un batch de datos de manera automática o manual.\n",
    "* Realizar la carga de datos en un proceso o en múltiples procesos.\n",
    "* Ubicar los tensores en memoria page-locked para agilizar su transferencia a la GPU.\n",
    "\n",
    "A continuación, creamos una instancia de la clase torch.utils.data.DataLoader a la que pasamos el objeto dataset que hemos creado. Definimos un tamaño de batch de 10 y shuffle=False para que no se cambio el orden de los datos en cada epoch (recorrido completo de los datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "390df99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number 1\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]) tensor([1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009])\n",
      "Batch number 2\n",
      "tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20]) tensor([1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019])\n",
      "Batch number 3\n",
      "tensor([21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) tensor([1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029])\n",
      "Batch number 4\n",
      "tensor([31, 32, 33, 34, 35, 36, 37, 38, 39, 40]) tensor([1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039])\n",
      "Batch number 5\n",
      "tensor([41, 42, 43, 44, 45, 46, 47, 48, 49, 50]) tensor([1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049])\n",
      "Batch number 6\n",
      "tensor([51, 52, 53, 54, 55, 56, 57, 58, 59, 60]) tensor([1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059])\n",
      "Batch number 7\n",
      "tensor([61, 62, 63, 64, 65, 66, 67, 68, 69, 70]) tensor([1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069])\n",
      "Batch number 8\n",
      "tensor([71, 72, 73, 74, 75, 76, 77, 78, 79, 80]) tensor([1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079])\n",
      "Batch number 9\n",
      "tensor([81, 82, 83, 84, 85, 86, 87, 88, 89, 90]) tensor([1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089])\n",
      "Batch number 10\n",
      "tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100]) tensor([1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099])\n",
      "Batch number 11\n",
      "tensor([101, 102, 103, 104, 105, 106, 107, 108, 109, 110]) tensor([1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109])\n"
     ]
    }
   ],
   "source": [
    "batch_size=10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for i, (numbers, labels) in enumerate(train_loader):\n",
    "  if  i<11:\n",
    "    print('Batch number %d'%(i+1))\n",
    "    print(numbers, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50380357",
   "metadata": {},
   "source": [
    "Ahora, creamos otra instancia pero con shuffle=True para que se cambie el orden de los datos en cada epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0cb186b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number 1\n",
      "tensor([517, 429, 502, 934, 940, 910, 811, 543, 646, 461]) tensor([1516, 1428, 1501, 1933, 1939, 1909, 1810, 1542, 1645, 1460])\n",
      "Batch number 2\n",
      "tensor([691, 150, 355, 448, 666, 660,  51, 246, 662, 618]) tensor([1690, 1149, 1354, 1447, 1665, 1659, 1050, 1245, 1661, 1617])\n",
      "Batch number 3\n",
      "tensor([414, 603, 475, 673, 928, 690, 552, 967, 279, 295]) tensor([1413, 1602, 1474, 1672, 1927, 1689, 1551, 1966, 1278, 1294])\n",
      "Batch number 4\n",
      "tensor([629, 525, 152, 885, 773, 972, 305, 917, 977, 644]) tensor([1628, 1524, 1151, 1884, 1772, 1971, 1304, 1916, 1976, 1643])\n",
      "Batch number 5\n",
      "tensor([491, 138, 349, 451, 891,  12, 649, 816, 387, 421]) tensor([1490, 1137, 1348, 1450, 1890, 1011, 1648, 1815, 1386, 1420])\n",
      "Batch number 6\n",
      "tensor([287,  80, 542, 740, 177,  67, 213, 687, 767,   2]) tensor([1286, 1079, 1541, 1739, 1176, 1066, 1212, 1686, 1766, 1001])\n",
      "Batch number 7\n",
      "tensor([465, 860,  26, 189, 941, 746, 747, 425, 930,  61]) tensor([1464, 1859, 1025, 1188, 1940, 1745, 1746, 1424, 1929, 1060])\n",
      "Batch number 8\n",
      "tensor([545,  77, 400, 779, 442, 145, 677, 507, 424, 350]) tensor([1544, 1076, 1399, 1778, 1441, 1144, 1676, 1506, 1423, 1349])\n",
      "Batch number 9\n",
      "tensor([ 49, 614, 102, 591, 125, 324, 358, 876, 715, 986]) tensor([1048, 1613, 1101, 1590, 1124, 1323, 1357, 1875, 1714, 1985])\n",
      "Batch number 10\n",
      "tensor([617, 333, 741, 551, 235, 436, 737, 411,  11, 803]) tensor([1616, 1332, 1740, 1550, 1234, 1435, 1736, 1410, 1010, 1802])\n",
      "Batch number 11\n",
      "tensor([586, 205,  87, 611,  78, 670, 310, 699, 554, 510]) tensor([1585, 1204, 1086, 1610, 1077, 1669, 1309, 1698, 1553, 1509])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for i, (numbers, labels) in enumerate(train_loader):\n",
    "  if  i<11:\n",
    "    print('Batch number %d'%(i+1))\n",
    "    print(numbers, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
